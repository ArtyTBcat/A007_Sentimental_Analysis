{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-24T12:02:45.147075Z",
     "start_time": "2024-04-24T12:02:45.134062900Z"
    }
   },
   "outputs": [],
   "source": [
    "import json, os\n",
    "#@ Downloading the Libraries and Dependencies:\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, json, string, os\n",
    "import collections\n",
    "\n",
    "from argparse import Namespace\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "#@ loading datasets\n",
    "file_path = os.path.join(\"E:/Necleotide Codes/archive\", \"yelp_academic_dataset_checkin.json\")\n",
    "data_file = open(file_path)\n",
    "data = []\n",
    "for line in data_file:\n",
    "    data.append(json.loads(line))\n",
    "checkin_df = pd.DataFrame(data)\n",
    "data_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T12:02:46.342481Z",
     "start_time": "2024-04-24T12:02:45.147075Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'stars'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[40], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m filtered_data \u001B[38;5;241m=\u001B[39m [{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstars\u001B[39m\u001B[38;5;124m\"\u001B[39m: item[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstars\u001B[39m\u001B[38;5;124m\"\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m: item[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m]} \u001B[38;5;28;01mfor\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m data]\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Create DataFrame\u001B[39;00m\n\u001B[0;32m      4\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(filtered_data)\n",
      "Cell \u001B[1;32mIn[40], line 1\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[1;32m----> 1\u001B[0m filtered_data \u001B[38;5;241m=\u001B[39m [{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstars\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mitem\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstars\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m: item[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m]} \u001B[38;5;28;01mfor\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m data]\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Create DataFrame\u001B[39;00m\n\u001B[0;32m      4\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(filtered_data)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'stars'"
     ]
    }
   ],
   "source": [
    "\n",
    "filtered_data = [{\"stars\": item[\"stars\"], \"text\": item[\"text\"]} for item in data]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(filtered_data)\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df.drop(\"stars\", axis=1)  # Features (text)\n",
    "y = df[\"stars\"]  # Target variable (stars)\n",
    "\n",
    "# Split the data into training and testing sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Convert training and testing sets to list of dictionaries\n",
    "train_review = pd.DataFrame({**{\"stars\": stars}, **record} for stars, record in zip(y_train, X_train.to_dict(orient=\"records\")))\n",
    "\n",
    "print(train_review)\n",
    "\n",
    "test_review = [{**{\"stars\": stars}, **record} for stars, record in zip(y_test, X_test.to_dict(orient=\"records\"))]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T12:02:46.404041800Z",
     "start_time": "2024-04-24T12:02:46.342481Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-24T12:02:46.374015Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
